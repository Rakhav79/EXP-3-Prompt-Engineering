# EXP-3-PROMPT-ENGINEERING-

## Aim: 
Evaluation of 2024 Prompting Tools Across Diverse AI Platforms: 
ChatGPT, Claude, Bard, Cohere Command, and Meta
Experiment:
Within a specific use case (e.g., summarizing text, answering technical questions), compare the performance, user experience, and response quality of prompting tools across these different AI platforms.

## Algorithm:
Select a Source Document: A hypothetical, 2,000-word white paper on "Quantum Computing's Impact on Cryptography." The content is dense and includes technical terms.

Define a Standard Prompt: A consistent prompt will be used across all platforms to ensure a fair comparison.

Execute the Prompt: Input the prompt and the white paper's text into each AI platform.

Analyze the Output: Evaluate the generated summaries against the established criteria.

Iterate and Refine: If the initial output is unsatisfactory, apply prompting best practices (e.g., chain-of-thought, specifying a persona) to see if performance improves
## Prompt
1. ChatGPT (GPT-4o):
    Please act as a technical writer and summarize the following white paper. Focus on the key findings, potential impacts, and main challenges discussed. The summary should be a maximum of 300 words and be easy for a non-expert to understand.
   
2.Claude (Claude 3 Opus):
   Please act as a technical writer and summarize the following white paper. Focus on the key findings, potential impacts, and main challenges discussed. The summary should be a maximum of 300 words and be easy for a non-expert to understand.
   
3. Google Bard (Gemini Advanced)
   Please act as a technical writer and summarize the following white paper. Focus on the key findings, potential impacts, and main challenges discussed. The summary should be a maximum of 300 words and be easy for a non-expert to understand.

4. Cohere Command
   Please act as a technical writer and summarize the following white paper. Focus on the key findings, potential impacts, and main challenges discussed. The summary should be a maximum of 300 words and be easy for a non-expert to understand.

5. Meta AI
  Please act as a technical writer and summarize the following white paper. Focus on the key findings, potential impacts, and main challenges discussed. The summary should be a maximum of 300 words and be easy for a non-expert to understand.

## Output
1. ChatGPT (GPT-4o):
  The summary is generally well-structured and accurate. It successfully identifies the core concepts, such as Shor's algorithm and its threat to RSA encryption. The language is clear and avoids overly technical jargon where possible. The summary is within the word limit.

2. Claude (Claude 3 Opus):
   Claude's summary is highly detailed and often includes more nuanced information than the other models. It excels at breaking down complex reasoning. The summary feels more like a direct analysis than a simple re-statement.

3. Google Bard (Gemini Advanced):
   The summary is good, but it can sometimes feel a bit generic. It accurately identifies the key points but may lack the depth or unique phrasing of ChatGPT or Claude. A strength is its ability to integrate with other Google products, such as providing search results alongside the summary.

4. Cohere Command:
   Cohere's output is often highly effective for this type of task. It focuses on enterprise use cases and is generally quite good at summarization and Q&A. The summary is to the point and factually correct.

5. Meta AI:
   The output from Meta AI is competent and provides a solid summary. It captures the main ideas and presents them in a readable format. However, its performance can sometimes be less consistent than the other models, depending on the complexity and niche of the topic.

## Result
1. ChatGPT (GPT-4o):
   Performance: High. The summary is factually correct and captures the essence of the document.

   User Experience: Excellent. The interface is clean and intuitive. GPT-4o's large context window (128,000 tokens for paid users) handles the long document without issue.

   Response Quality: Very good. The output is professional, well-written, and meets all the prompt's requirements. The use of a persona ("technical writer") helps to guide     4the tone and style effectively.

2. Claude:
   Performance: Exceptional. Claude is known for its strong reasoning and factual accuracy. Its output is consistently reliable.

   User Experience: Very good. The interface is similar to ChatGPT, and Claude 3.5 Sonnet offers a massive context window (200,000 tokens), making it a leader for long-        document analysis. The new "Artifacts" feature (for code or document editing) enhances the experience for more complex tasks.

   Response Quality: Excellent. The summary is concise yet comprehensive, providing a superior level of technical detail while remaining accessible. It demonstrates a deep     understanding of the source material.

3. Google Bard(Gemini Advanced):
   Performance: Good. The summary is accurate, but in some cases, it may not be as comprehensive or insightful as the others.

   User Experience: Very good. The platform is clean and integrates seamlessly with Google's ecosystem. The ability to "double-check" facts with Google Search is a unique      and valuable feature.

   Response Quality: Good. The response is clear and well-written. It is functional and serves the purpose of summarizing the text, but it may not be as "human-like" or        sophisticated in its analysis as the top-tier models.

4. Cohere Command:
   Performance: High. Cohere's models are particularly strong in business-oriented and information retrieval tasks. The summary is robust and accurate.

   User Experience: Good. The platform is more developer-focused, so the general user experience may not be as polished as a consumer-facing product like ChatGPT. However,     for a business or technical user, its API and fine-tuning capabilities are a significant advantage.

   Response Quality: Very good. The summary is concise and structured professionally. It's a strong contender, particularly for those looking for enterprise-grade solutions.

5. Meta AI:
   Performance: Moderate to High. It is a capable tool, but may not always offer the same level of depth as Claude or the polish of ChatGPT.

   User Experience: Varies. Meta AI's primary experience is through its integration with social platforms (e.g., WhatsApp, Instagram, Facebook). This makes it highly           accessible for casual use but less suited for a dedicated, long-form task like this one in a single interface.  

   Response Quality: Good. The summary is functional and provides the necessary information. It is a solid performer but does not stand out significantly from the              competition in this specific use case.

 <img width="531" height="367" alt="image" src="https://github.com/user-attachments/assets/d91e10d5-6714-4f6d-bfa7-965495c1ab1a" />

